# RLM

强化学习解决迷宫问题

[EN](../README.md) | 中文

## 简介

本项目的迷宫问题中，Agent 几乎对环境一无所知，除了：

1. 自身的位置
2. 迷宫是方形的且存在一个可到达的终点
3. Agent 触碰到墙壁/出界时死亡，并且回到起点重新开始

本项目使用了一些基础的强化学习算法解决上面的问题。

## UML 类图

![img](./class_diagram.png)

## 功能介绍

### 强化学习算法

- [x] Q 学习
- [x] SARSA
- [x] 价值迭代
- [x] 策略迭代

> 当我们为每个算法做优化的时候，我们发现这些基础的，不依赖神经网络的 RL 算法的决策与学习模型十分类似。

### 迷宫生成算法

- [x] Kruskal Algorithm
- [x] Recursively Walk
- [ ] DFS
- [ ] Prim Algorithm
- [ ] Recursively Divide

### 用户界面

- [x] 画出迷宫
- [x] 自由的算法选择
- [x] 随机生成指定大小的迷宫
- [x] 显示迭代次数（Agent 未到达终点就死亡并重启的次数）
- [x] 解决后显示路径
- [x] 暂停按钮